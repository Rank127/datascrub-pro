# ===========================================
# DataScrub Pro - Environment Variables
# ===========================================
# Copy this file to .env.local and fill in your values

# ----- DATABASE -----
# Get from Supabase: Project Settings > Database > Connection string
# Use "Transaction" mode for DATABASE_URL (port 6543)
DATABASE_URL="postgresql://postgres.[PROJECT-ID]:[PASSWORD]@aws-0-us-east-1.pooler.supabase.com:6543/postgres?pgbouncer=true"
# Use "Session" mode for DIRECT_URL (port 5432) - needed for migrations
DIRECT_URL="postgresql://postgres.[PROJECT-ID]:[PASSWORD]@aws-0-us-east-1.pooler.supabase.com:5432/postgres"

# ----- AUTHENTICATION -----
# Generate with: openssl rand -base64 32
AUTH_SECRET="your-auth-secret-here-generate-with-openssl"
AUTH_URL="https://yourdomain.com"

# ----- ENCRYPTION -----
# Generate with: openssl rand -hex 32
ENCRYPTION_KEY="your-64-character-hex-encryption-key-here"

# ----- EXTERNAL APIS -----
# Anthropic Claude API (for AI-powered ticketing agent)
# Get from https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=""

# HaveIBeenPwned API (optional, $3.50/month at https://haveibeenpwned.com/API/Key)
HIBP_API_KEY=""

# LeakCheck API (paid API for breach database scanning)
# Get from https://leakcheck.io/api
# Features: email, phone, and username breach lookups with detailed results
# Rate limit: 10 requests/minute (handled automatically with queue)
LEAKCHECK_API_KEY=""

# ScrapingBee API (optional, for reliable data broker scanning)
# Get from https://www.scrapingbee.com (free tier: 1000 credits/month)
# Without this, data broker scanners use direct HTTP which may be blocked
SCRAPINGBEE_API_KEY=""

# ----- STRIPE (for payments) -----
# Get from https://dashboard.stripe.com/apikeys
STRIPE_SECRET_KEY=""
STRIPE_PUBLISHABLE_KEY=""
STRIPE_WEBHOOK_SECRET=""

# ----- EMAIL (optional) -----
# Get from https://resend.com
RESEND_API_KEY=""

# ----- APP CONFIG -----
NEXT_PUBLIC_APP_URL="https://yourdomain.com"
NEXT_PUBLIC_APP_NAME="DataScrub Pro"

# ----- ANALYTICS -----
# Google Analytics 4 Measurement ID (optional)
# Get from https://analytics.google.com > Admin > Data Streams > Measurement ID
NEXT_PUBLIC_GA_MEASUREMENT_ID=""

# ----- VERCEL INTEGRATION (Admin Dashboard) -----
# Access token from https://vercel.com/account/tokens
VERCEL_ACCESS_TOKEN=""
# Project ID from Vercel dashboard (Project Settings > General)
VERCEL_PROJECT_ID=""
# Optional: Team ID if using team account
VERCEL_TEAM_ID=""

# ----- GOOGLE ANALYTICS DATA API (Admin Dashboard) -----
# For server-side analytics in admin dashboard
# 1. Create Google Cloud project
# 2. Enable Analytics Data API
# 3. Create service account with Analytics Viewer role
# 4. Download JSON key and base64 encode: cat key.json | base64
# 5. Add service account email to GA4 property (Admin > Property Access Management)
GOOGLE_SERVICE_ACCOUNT_KEY=""
# GA4 Property ID (format: properties/123456789)
# Get from GA4 Admin > Property Settings > Property ID
GA_PROPERTY_ID=""

# ----- TWILIO (SMS Notifications) -----
# Get from https://console.twilio.com
TWILIO_ACCOUNT_SID=""
TWILIO_AUTH_TOKEN=""
TWILIO_PHONE_NUMBER=""  # Your Twilio phone number (e.g., +1234567890)
TWILIO_VERIFY_SERVICE_SID=""  # Create at: console.twilio.com/us1/develop/verify/services

# ----- REDIS/UPSTASH (Optional - for job queues) -----
# Standard Redis URL
REDIS_URL=""
# Or Upstash Redis REST API
UPSTASH_REDIS_REST_URL=""
UPSTASH_REDIS_REST_TOKEN=""
